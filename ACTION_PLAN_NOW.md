# ğŸ¯ IMMEDIATE ACTION PLAN - Run These Commands Now

## Your Analysis Is Spot-On - Here's The Execution Order

Based on ROI and risk reduction, here's what to do **right now**:

---

## ğŸš€ **Phase 1: Diagnose (10 minutes)**

Run these three diagnostic scripts to see what needs fixing:

### **1a. Check PIT Filtering (2 min)**

```powershell
python diagnose_pit_filtering.py
```

**What you'll learn:**
- Do trials have date fields? (Probably not - that's why PIT filtered = 0)
- Which date field has best coverage
- What the impact is

**Expected output:**
```
âŒ last_update_posted: 0/464 (0.0%)
âŒ source_date: 0/464 (0.0%)
âŒ ANY date field: 0/464 (0.0%)

âŒ CRITICAL: <10% of trials have date fields
```

### **1b. Check Module 2 Coverage (2 min)**

```powershell
python diagnose_module2_coverage.py
```

**What you'll learn:**
- Why Module 2 shows "Scored: 0"
- Field name mismatch? Missing file? Missing data?

**Expected output:**
```
âŒ financial.json NOT FOUND
âœ… Financial data exists in universe.json!
   With 'financial_data' field: 98/98 (100%)

SOLUTION: Transform universe.json â†’ financial_records.json
```

### **1c. Check Current Output (2 min)**

```powershell
python production_validation.py screening_FINAL.json
```

**What you'll learn:**
- Which invariants are failing
- Module coverage percentages
- What needs immediate attention

**Expected output:**
```
âœ… Weight Sum: 0.9000 (expected 0.9000)
âœ… Excluded Weights: 0.0000
âš ï¸  Module 2 (Financial): 0/98 (0%)  â† FIX THIS
âš ï¸  Module 3 (Catalyst): 0/98 (0%)
âœ… Module 4 (Clinical): 98/98 (100%)
âš ï¸  WARNING: 464 trials but PIT filtered 0  â† NOTE THIS
```

---

## ğŸ”§ **Phase 2: Quick Wins (15 minutes)**

### **2a. Enable Top-N Selection (5 min) - HIGHEST ROI**

This is literally a one-parameter change with massive impact.

```powershell
# Find where to add it
Select-String -Path *.py -Pattern "enrich_with_defensive_overlays" | Select-Object Filename, LineNumber

# Then add top_n=60 parameter to the call with REAL data
```

**Impact:**
- Max weight: 3.69% â†’ 5.20% (+41%)
- Top 10 concentration: 24.7% â†’ 32.5%
- Better conviction expression

**Test it:**
```powershell
python run_screen.py --as-of-date 2026-01-06 --data-dir production_data --output screening_TOP60.json

# Should see: Max weight: 0.0520 (5.20%)
```

### **2b. Fix Module 2 Financial Coverage (10 min)**

Based on diagnostic, you probably need to transform universe.json:

```powershell
# If diagnostic said "financial.json NOT FOUND":
python diagnose_module2_coverage.py --fix

# This creates: production_data/financial_records.json

# Then update run_screen.py line 162:
# FROM: financial_records = load_json_data(data_dir / "financial.json", ...)
# TO:   financial_records = load_json_data(data_dir / "financial_records.json", ...)
```

**Re-run and check:**
```powershell
python run_screen.py --as-of-date 2026-01-06 --data-dir production_data --output screening_M2_FIXED.json

# Should see: Module 2 (Financial): 95/98 (97%)  â† Much better!
```

---

## ğŸ“Š **Phase 3: Medium Priority (30 minutes)**

### **3a. Add Production Validation (15 min)**

Add to end of `run_screen.py`:

```python
# At the top:
from production_validation import validate_screening_output

# At the end of run_screening_pipeline():
    # ... existing code that creates output dict ...
    
    # VALIDATE BEFORE RETURNING
    config = {
        'cash_target': '0.10',
        'top_n': 60,  # Or None if not enabled yet
    }
    
    validate_screening_output(output, as_of_date, config)
    
    return output
```

**Now every run will show:**
```
================================================================================
PRODUCTION VALIDATION
================================================================================

âœ… Weight Sum: 0.9000 (expected 0.9000, diff 0.0000)
âœ… Excluded weight sum: 0.0000 (expected 0.0000)
âœ… Top-N count: 60 (expected 60)

ğŸ“Š Module Coverage:
  Module 1 (Universe):  98 active
  âœ… Module 2 (Financial): 95/98 (97%)
  âš ï¸  Module 3 (Catalyst):  0/98 (0%)
  âœ… Module 4 (Clinical):  98/98 (100%)

âš ï¸  WARNING: 464 trials but PIT filtered 0
   This suggests trials missing date fields

ğŸ“… Data Dates:
  Analysis date: 2026-01-06
  All modules match: True
```

**This catches future regressions immediately!**

### **3b. Add PIT Diagnostics to Module 4 (15 min)**

In `module_4_clinical_dev.py`, after the PIT filtering loop, add:

```python
def compute_module_4_clinical_dev(trial_records, active_tickers, as_of_date):
    # ... existing code ...
    pit_cutoff = compute_pit_cutoff(as_of_date)
    
    # NEW: Count date coverage
    trials_with_dates = sum(1 for t in trial_records if t.get('last_update_posted') or t.get('source_date'))
    
    if trials_with_dates > 0:
        date_values = [
            t.get('last_update_posted') or t.get('source_date')
            for t in trial_records
            if t.get('last_update_posted') or t.get('source_date')
        ]
        min_date = min(date_values) if date_values else None
        max_date = max(date_values) if date_values else None
    else:
        min_date = max_date = None
    
    # Group trials by ticker...
    # ... existing grouping code ...
    
    # NEW: Add to diagnostic_counts
    return {
        "as_of_date": as_of_date,
        "scores": sorted(scores, key=lambda x: x["ticker"]),
        "diagnostic_counts": {
            "scored": len(scores),
            "total_trials": sum(len(v) for v in ticker_trials.values()),
            "pit_filtered": pit_filtered_count,
            "trials_with_dates": trials_with_dates,  # NEW
            "date_coverage_pct": round(trials_with_dates / len(trial_records) * 100, 1) if trial_records else 0,  # NEW
            "date_range_min": min_date,  # NEW
            "date_range_max": max_date,  # NEW
        },
        "provenance": create_provenance(RULESET_VERSION, {"tickers": active_tickers}, pit_cutoff),
    }
```

**Now you'll see:**
```
[5/6] Module 4: Clinical development...
  Scored: 98, Trials evaluated: 464, PIT filtered: 0
  Date coverage: 0.0% (0/464 trials with dates)  â† RED FLAG!
```

---

## ğŸ”® **Phase 4: Future (Can Wait)**

### **4a. Fix PIT Date Collection (60 min)**

Update `collect_all_universe_data.py` to actually collect dates from ClinicalTrials.gov API.

See `diagnose_pit_filtering.py --show-fix` for exact code.

**Impact:** Historical accuracy, proper lookahead prevention

**Urgency:** Low if only screening current date

### **4b. Fix Module 3 Catalyst (60 min)**

Either:
- Create catalyst data from trial readout dates
- Add external catalyst source (conference dates, FDA decision dates)
- Use placeholder data

**Impact:** Better near-term catalyst identification

**Urgency:** Medium (system works without it)

---

## ğŸ“‹ **Priority Stack (Do In This Order):**

### **Today (30 min):**
1. âœ… Run diagnostics (10 min) - Know what's broken
2. ğŸ¯ Enable top-N (5 min) - **Instant 41% weight increase**
3. ğŸ”§ Fix Module 2 (15 min) - **Most important for stable rankings**

### **This Week:**
4. ğŸ“Š Add production validation (15 min)
5. ğŸ—“ï¸ Add PIT diagnostics to Module 4 (15 min)

### **When You Need Historical Analysis:**
6. ğŸ”® Fix PIT date collection (60 min)
7. ğŸ¯ Fix Module 3 catalysts (60 min)

---

## ğŸ¯ **Run This Right Now:**

```powershell
# 1. Run diagnostics
python diagnose_pit_filtering.py > pit_diagnostic.txt
python diagnose_module2_coverage.py > m2_diagnostic.txt
python production_validation.py screening_FINAL.json > validation.txt

# 2. Review outputs
Get-Content pit_diagnostic.txt
Get-Content m2_diagnostic.txt
Get-Content validation.txt

# 3. Share outputs with me and I'll give you exact fix commands
```

---

## ğŸ’¡ **Why This Order?**

**Top-N first:**
- One line change
- Immediate material impact
- No dependencies
- Can't break anything

**Module 2 second:**
- Financial health is core driver
- Highest impact on ranking stability
- Same fix pattern we just used successfully
- Unlocks better scores

**Production validation third:**
- Prevents future regressions
- One-time investment
- Permanent benefit
- Makes system self-monitoring

**PIT dates last:**
- Only needed for historical analysis
- Low urgency for current-date screening
- More complex to fix
- System works without it (just less rigorous)

---

## ğŸš€ **Your Next Command:**

```powershell
# Start with diagnostics:
python diagnose_module2_coverage.py
```

**Then share the output and I'll give you the exact fix!**

You're 30 minutes from:
- âœ… 5.2% max weights (better conviction)
- âœ… 95%+ financial coverage
- âœ… Production-grade validation
- âœ… Self-monitoring system
